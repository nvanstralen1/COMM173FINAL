# -*- coding: utf-8 -*-
"""Final Project Proposal

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/140Xb13HwT9ny6udLMwt_quco8sj2fwcP
"""

#Data: This section will describe my procedures for collecting my data.

pip install selenium

pip install pandas

from selenium import webdriver
import pandas as pd
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.keys import Keys
import time

url = 'https://www.youtube.com/results?search_query=frozen+food+at+trader+joes'

driver = webdriver.Chrome()
driver.get(url)

def scroll_to_bottom(driver):
    old_position = 0
    new_position = None
    
    while (new_position != old_position):
        # Get old scroll position
        old_position = driver.execute_script(("return (window.pageYOffset !== undefined) ?"
                                            " window.pageYOffset : (document.documentElement ||"
                                            " document.body.parentNode || document.body);"))
        # Sleep and scroll
        time.sleep(5)
        driver.execute_script(("var scrollingElement = (document.scrollingElement ||"
                              " document.body);scrollingElement.scrollTop = "
                              " scrollingElement.scrollHeight"))
        
        time.sleep(5)
        # Get new position
        new_position = driver.execute_script(("return (window.pageYOffset !== undefined) ?"
                                             " window.pageYOffset : (document.documentElement ||"
                                             " document.body.parentNode || documentBody);"))

scroll_to_bottom(driver)

user_data = driver.find_elements(by=By.XPATH,value='//*[@id="video-title"]')

print(len(user_data))

links = []
for i in user_data:
    if (i.get_attribute('href') != None):
        links.append(i.get_attribute('href'))

print(len(links))

df = pd.DataFrame(columns = ['link', 'title', 'views', 'likes' , 'brand' , 'date'])

v_category = "frozen_food_traderjoes"
wait = WebDriverWait(driver, 50)
for x in links:
    driver.get(x)
    v_id = x
    v_title = wait.until(EC.presence_of_element_located(
                   (By.CSS_SELECTOR,"h1.style-scope.ytd-watch-metadata yt-formatted-string"))).text

    v_description =  wait.until(EC.presence_of_element_located(
                                (By.CSS_SELECTOR,"div#snippet yt-formatted-string"))).text
    df.loc[len(df)] = [v_id, v_title, v_description, v_category]

driver.quit()

print(df)

df.to_csv('comm173_final.csv', index=False)

#Data Preparation: This section will describe my procedures for preparing my data

import pandas as pd

df = pd.read_csv('comm173_final.csv')

columns_to_drop = ['comments',]  
df = df.drop(columns=columns_to_drop)

df = df.drop_duplicates()

df = df.dropna()

df['date'] = pd.to_datetime(df['date'])

string_columns = ['title', 'likes', 'views', 'brand', 'date']  
df[string_columns] = df[string_columns].str.strip()

df['views'] = (df['views'] - df['views'].min()) / (df['views'].max() - df['views'].min())

df.to_csv('comm173_final.csv', index=False)

#Analysis: This section will describe my procedures for preparing my data

import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv('comm173_final.csv')

likes = df['likes']
views = df['views']

correlation_coefficient = likes.corr(views)

print("Correlation coefficient between likes and views:", correlation_coefficient)

plt.scatter(views, likes)
plt.xlabel('Views')
plt.ylabel('Likes')
plt.title('Correlation between Likes and Views')
plt.show()